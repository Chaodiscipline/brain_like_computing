{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import torchvision as tv\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 2.316\n",
      "epoch: 0, loss: 2.504\n",
      "epoch: 0, loss: 2.475\n",
      "epoch: 0, loss: 2.303\n",
      "epoch: 0, loss: 2.319\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a6267e5f0a84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mc2_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mc2_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc2_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a6267e5f0a84>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;34m\"\"\"Run through everything and concatenate the output of the C2s.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0mc2_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_all_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         c2_outputs = torch.cat(\n\u001b[0;32m    245\u001b[0m             [c2_out[:, None, :] for c2_out in c2_outputs], 1)\n",
      "\u001b[1;32m<ipython-input-2-a6267e5f0a84>\u001b[0m in \u001b[0;36mrun_all_layers\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_all_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0ms1_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms1_units\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;31m# Each C1 layer pools across two S1 layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a6267e5f0a84>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_all_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0ms1_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms1_units\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;31m# Each C1 layer pools across two S1 layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a6267e5f0a84>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;34m\"\"\"Apply Gabor filters, take absolute value, and normalize.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0ms1_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgabor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnorm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# To avoid divide by zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 338\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def gabor_filter(size, wavelength, orientation):\n",
    "    \n",
    "    lambda_ = size * 2. / wavelength\n",
    "    sigma = lambda_ * 0.8\n",
    "    gamma = 0.3  # spatial aspect ratio: 0.23 < gamma < 0.92\n",
    "    theta = np.deg2rad(orientation + 90)\n",
    "\n",
    "    # Generate Gabor filter\n",
    "    x, y = np.mgrid[:size, :size] - (size // 2)\n",
    "    rotx = x * np.cos(theta) + y * np.sin(theta)\n",
    "    roty = -x * np.sin(theta) + y * np.cos(theta)\n",
    "    filt = np.exp(-(rotx**2 + gamma**2 * roty**2) / (2 * sigma ** 2))\n",
    "    filt *= np.cos(2 * np.pi * rotx / lambda_)\n",
    "    filt[np.sqrt(x**2 + y**2) > (size / 2)] = 0\n",
    "\n",
    "    # Normalize the filter\n",
    "    filt = filt - np.mean(filt)\n",
    "    filt = filt / np.sqrt(np.sum(filt ** 2))\n",
    "\n",
    "    return filt\n",
    "\n",
    "class S1(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, wavelength, orientations=[90, -45, 0, 45]):\n",
    "        super().__init__()\n",
    "        self.num_orientations = len(orientations)\n",
    "        self.size = size\n",
    "\n",
    "# Use PyTorch's Conv2d as a base object. Each \"channel\" will be an\n",
    "        # orientation.\n",
    "        self.gabor = nn.Conv2d(1, self.num_orientations, size,\n",
    "                               padding=size // 2, bias=False)\n",
    "\n",
    "        # Fill the Conv2d filter weights with Gabor kernels: one for each\n",
    "        # orientation\n",
    "        for channel, orientation in enumerate(orientations):\n",
    "            self.gabor.weight.data[channel, 0] = torch.Tensor(\n",
    "                gabor_filter(size, wavelength, orientation))\n",
    "\n",
    "        # A convolution layer filled with ones. This is used to normalize the\n",
    "        # result in the forward method.\n",
    "        self.uniform = nn.Conv2d(1, 4, size, padding=size // 2, bias=False)\n",
    "        nn.init.constant_(self.uniform.weight, 1)\n",
    "\n",
    "        # Since everything is pre-computed, no gradient is required\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"Apply Gabor filters, take absolute value, and normalize.\"\"\"\n",
    "        s1_output = torch.abs(self.gabor(img))\n",
    "        norm = torch.sqrt(self.uniform(img ** 2))\n",
    "        norm.data[norm == 0] = 1  # To avoid divide by zero\n",
    "        s1_output /= norm\n",
    "        return s1_output\n",
    "\n",
    "class C1(nn.Module):\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.local_pool = nn.MaxPool2d(size, stride=size // 2,\n",
    "                                       padding=size // 2)\n",
    "\n",
    "\n",
    "    def forward(self, s1_outputs):\n",
    "        \"\"\"Max over scales, followed by a MaxPool2d operation.\"\"\"\n",
    "        s1_outputs = torch.cat([out.unsqueeze(0) for out in s1_outputs], 0)\n",
    "\n",
    "        # Pool over all scales\n",
    "        s1_output, _ = torch.max(s1_outputs, dim=0)\n",
    "\n",
    "        # Pool over local (c1_space x c1_space) neighbourhood\n",
    "        return self.local_pool(s1_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class S2(nn.Module):\n",
    "    \n",
    "    def __init__(self, patches, activation='gaussian', sigma=1):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.sigma = sigma\n",
    "\n",
    "        num_patches, num_orientations, size, _ = patches.shape\n",
    "\n",
    "        # Main convolution layer\n",
    "        self.conv = nn.Conv2d(in_channels=num_orientations,\n",
    "                              out_channels=num_orientations * num_patches,\n",
    "                              kernel_size=size,\n",
    "                              padding=size // 2,\n",
    "                              groups=num_orientations,\n",
    "                              bias=False)\n",
    "        self.conv.weight.data = torch.Tensor(\n",
    "            patches.transpose(1, 0, 2, 3).reshape(1600, 1, size, size))\n",
    "\n",
    "        # A convolution layer filled with ones. This is used for the distance\n",
    "        # computation\n",
    "        self.uniform = nn.Conv2d(1, 1, size, padding=size // 2, bias=False)\n",
    "        nn.init.constant_(self.uniform.weight, 1)\n",
    "\n",
    "        # This is also used for the distance computation\n",
    "        self.patches_sum_sq = nn.Parameter(\n",
    "            torch.Tensor((patches ** 2).sum(axis=(1, 2, 3))))\n",
    "\n",
    "        self.num_patches = num_patches\n",
    "        self.num_orientations = num_orientations\n",
    "        self.size = size\n",
    "\n",
    "        # No gradient required for this layer\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, c1_outputs):\n",
    "        s2_outputs = []\n",
    "        for c1_output in c1_outputs:\n",
    "            conv_output = self.conv(c1_output)\n",
    "\n",
    "            # Unstack the orientations\n",
    "            conv_output_size = conv_output.shape[3]\n",
    "            conv_output = conv_output.view(\n",
    "                -1, self.num_orientations, self.num_patches, conv_output_size,\n",
    "                conv_output_size)\n",
    "\n",
    "            # Pool over orientations\n",
    "            conv_output = conv_output.sum(dim=1)\n",
    "\n",
    "            # Compute distance\n",
    "            c1_sq = self.uniform(\n",
    "                torch.sum(c1_output ** 2, dim=1, keepdim=True))\n",
    "            dist = c1_sq - 2 * conv_output\n",
    "            dist += self.patches_sum_sq[None, :, None, None]\n",
    "\n",
    "            # Apply activation function\n",
    "            if self.activation == 'gaussian':\n",
    "                dist = torch.exp(- 1 / (2 * self.sigma ** 2) * dist)\n",
    "            elif self.activation == 'euclidean':\n",
    "                dist[dist < 0] = 0  # Negative values should never occur\n",
    "                torch.sqrt_(dist)\n",
    "                dist = -dist\n",
    "            else:\n",
    "                raise ValueError(\"activation parameter should be either \"\n",
    "                                 \"'gaussian' or 'euclidean'.\")\n",
    "\n",
    "            s2_outputs.append(dist)\n",
    "        return s2_outputs\n",
    "\n",
    "\n",
    "class C2(nn.Module):\n",
    "    \"\"\"A layer of C2 units operating on a layer of S2 units.\"\"\"\n",
    "    def forward(self, s2_outputs):\n",
    "        \"\"\"Take the maximum value of the underlying S2 units.\"\"\"\n",
    "        maxs = [s2.max(dim=3)[0] for s2 in s2_outputs]\n",
    "        maxs = [m.max(dim=2)[0] for m in maxs]\n",
    "        maxs = torch.cat([m[:, None, :] for m in maxs], 1)\n",
    "        return maxs.max(dim=1)[0]\n",
    "\n",
    "\n",
    "class HMAX(nn.Module):\n",
    "    \n",
    "    def __init__(self, universal_patch_set, s2_act='gaussian'):\n",
    "        super().__init__()\n",
    "\n",
    "        # S1 layers, consisting of units with increasing size\n",
    "        self.s1_units = [\n",
    "            S1(size=7, wavelength=4),\n",
    "            S1(size=9, wavelength=3.95),\n",
    "            S1(size=11, wavelength=3.9),\n",
    "            S1(size=13, wavelength=3.85),\n",
    "            S1(size=15, wavelength=3.8),\n",
    "            S1(size=17, wavelength=3.75),\n",
    "            S1(size=19, wavelength=3.7),\n",
    "            S1(size=21, wavelength=3.65),\n",
    "            S1(size=23, wavelength=3.6),\n",
    "            S1(size=25, wavelength=3.55),\n",
    "            S1(size=27, wavelength=3.5),\n",
    "            S1(size=29, wavelength=3.45),\n",
    "            S1(size=31, wavelength=3.4),\n",
    "            S1(size=33, wavelength=3.35),\n",
    "            S1(size=35, wavelength=3.3),\n",
    "            S1(size=37, wavelength=3.25),\n",
    "        ]\n",
    "\n",
    "        # Explicitly add the S1 units as submodules of the model\n",
    "        for s1 in self.s1_units:\n",
    "            self.add_module('s1_%02d' % s1.size, s1)\n",
    "\n",
    "        # Each C1 layer pools across two S1 layers\n",
    "        self.c1_units = [\n",
    "            C1(size=8),\n",
    "            C1(size=10),\n",
    "            C1(size=12),\n",
    "            C1(size=14),\n",
    "            C1(size=16),\n",
    "            C1(size=18),\n",
    "            C1(size=20),\n",
    "            C1(size=22),\n",
    "        ]\n",
    "\n",
    "        # Explicitly add the C1 units as submodules of the model\n",
    "        for c1 in self.c1_units:\n",
    "            self.add_module('c1_%02d' % c1.size, c1)\n",
    "\n",
    "        # Read the universal patch set for the S2 layer\n",
    "        m = loadmat(universal_patch_set)\n",
    "        patches = [patch.reshape(shape[[2, 1, 0, 3]]).transpose(3, 0, 2, 1)\n",
    "                   for patch, shape in zip(m['patches'][0], m['patchSizes'].T)]\n",
    "\n",
    "        # One S2 layer for each patch scale, operating on all C1 layers\n",
    "        self.s2_units = [S2(patches=scale_patches, activation=s2_act)\n",
    "                         for scale_patches in patches]\n",
    "\n",
    "        # Explicitly add the S2 units as submodules of the model\n",
    "        for i, s2 in enumerate(self.s2_units):\n",
    "            self.add_module('s2_%d' % i, s2)\n",
    "\n",
    "        # One C2 layer operating on each scale\n",
    "        self.c2_units = [C2() for s2 in self.s2_units]\n",
    "\n",
    "        # Explicitly add the C2 units as submodules of the model\n",
    "        for i, c2 in enumerate(self.c2_units):\n",
    "            self.add_module('c2_%d' % i, c2)\n",
    "\n",
    "    def run_all_layers(self, img):\n",
    "        \n",
    "        s1_outputs = [s1(img) for s1 in self.s1_units]\n",
    "\n",
    "        # Each C1 layer pools across two S1 layers\n",
    "        c1_outputs = []\n",
    "        for c1, i in zip(self.c1_units, range(0, len(self.s1_units), 2)):\n",
    "            c1_outputs.append(c1(s1_outputs[i:i+2]))\n",
    "\n",
    "        s2_outputs = [s2(c1_outputs) for s2 in self.s2_units]\n",
    "        c2_outputs = [c2(s2) for c2, s2 in zip(self.c2_units, s2_outputs)]\n",
    "\n",
    "        return s1_outputs, c1_outputs, s2_outputs, c2_outputs\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"Run through everything and concatenate the output of the C2s.\"\"\"\n",
    "        c2_outputs = self.run_all_layers(img)[-1]\n",
    "        c2_outputs = torch.cat(\n",
    "            [c2_out[:, None, :] for c2_out in c2_outputs], 1)\n",
    "        return c2_outputs\n",
    "\n",
    "    def get_all_layers(self, img):\n",
    "        \n",
    "        s1_out, c1_out, s2_out, c2_out = self.run_all_layers(img)\n",
    "        return (\n",
    "            [s1.cpu().detach().numpy() for s1 in s1_out],\n",
    "            [c1.cpu().detach().numpy() for c1 in c1_out],\n",
    "            [[s2_.cpu().detach().numpy() for s2_ in s2] for s2 in s2_out],\n",
    "            [c2.cpu().detach().numpy() for c2 in c2_out],\n",
    "        )\n",
    "\n",
    "class Activation_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    在上面的simpleNet的基础上，在每层的输出部分添加了激活函数\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, n_hidden_1, out_dim):\n",
    "        super(Activation_Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, out_dim))\n",
    "        \"\"\"\n",
    "        这里的Sequential()函数的功能是将网络的层组合到一起。\n",
    "        \"\"\"\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "universal_patch_set = r'hmaxdata/universal_patch_set.mat'\n",
    "\n",
    "model = HMAX(universal_patch_set)\n",
    "\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x * 255),\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "learning_rate = 0.001\n",
    "num_epoches = 10\n",
    "\n",
    "# 定义训练数据集\n",
    "trainset = tv.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# 定义训练批处理数据\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    )\n",
    "\n",
    "# 定义测试数据集\n",
    "testset = tv.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transform)\n",
    "\n",
    "# 定义测试批处理数据\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    )\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "model2 = Activation_Net(8*400, 300, 10)\n",
    "model2 = model2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        c2_opt = model.forward(inputs)\n",
    "        c2_opt = c2_opt.view(c2_opt.size(0), -1)\n",
    "        \n",
    "        c2_opt = Variable(c2_opt)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        c2_opt = c2_opt.to(device)\n",
    "        labels = labels.to(device)\n",
    "            \n",
    "        out = model2(c2_opt)\n",
    "        loss = criterion(out, labels)\n",
    "        print_loss = loss.data.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch: {}, loss: {:.4}'.format(epoch, loss.data.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 554.444222,
   "position": {
    "height": "40px",
    "left": "582.444px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
